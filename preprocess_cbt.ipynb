{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing CER - Customer Behavior Trials (CBT) dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset comes from Smart Metering Electricity Customer Behaviour Trials project and can be requested from here: https://www.ucd.ie/issda/data/commissionforenergyregulationcer/. It comes in the form of 6 zip files which needs to be unzipped and excel file specifying the stimuli each customer was subjected to or whether he was in the control group and whether he was residential or SME customer (*SME and Residential allocations.xlsx*) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will unzip each file and select only the residential customers from the control group. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import zipfile\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = r\"path_to_your_folder_with_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(path_to_data + '\\SME and Residential allocations.xlsx')\n",
    "df = df[['ID', 'Code', 'Residential - Tariff allocation', 'Residential - stimulus allocation']]\n",
    "df = df[df['Code']==1]\n",
    "df = df[df['Residential - Tariff allocation']=='E']\n",
    "df = df[df['Residential - stimulus allocation']=='E']\n",
    "ids = df['ID'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We identified 929 client ids in the residential control group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "929"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.DataFrame()\n",
    "for i in range(1, 7):\n",
    "    with zipfile.ZipFile(path_to_data + f'\\File{i}.txt.zip', 'r') as zip_ref:\n",
    "        with zip_ref.open(f'File{i}.txt') as text_file:\n",
    "            df = pd.read_csv(text_file, sep=' ', header=None, names=['ID', 'datetime', 'power'])\n",
    "            df = df[df['ID'].isin(ids)]\n",
    "    df_all = pd.concat([df_all, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>datetime</th>\n",
       "      <th>power</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1152</th>\n",
       "      <td>1804</td>\n",
       "      <td>19601</td>\n",
       "      <td>0.102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1153</th>\n",
       "      <td>1804</td>\n",
       "      <td>19604</td>\n",
       "      <td>0.172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154</th>\n",
       "      <td>1804</td>\n",
       "      <td>19605</td>\n",
       "      <td>0.122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1155</th>\n",
       "      <td>1804</td>\n",
       "      <td>19602</td>\n",
       "      <td>0.175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1156</th>\n",
       "      <td>1804</td>\n",
       "      <td>19603</td>\n",
       "      <td>0.175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  datetime  power\n",
       "1152  1804     19601  0.102\n",
       "1153  1804     19604  0.172\n",
       "1154  1804     19605  0.122\n",
       "1155  1804     19602  0.175\n",
       "1156  1804     19603  0.175"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID          0\n",
       "datetime    0\n",
       "power       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the dataset the datetime is encoded in the following way: \n",
    "\n",
    "Five digit code:  \n",
    "- Day code: digits 1-3 (day 1 = 1st January 2009)\n",
    "- Time code: digits 4-5 (1-48 for each 30 minutes with 1= 00:00:00 â€“ 00:29:59)\n",
    " \n",
    "We want to decode it to regular datetime format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_datetime(codes):\n",
    "    day_codes = codes // 100\n",
    "    time_codes = codes % 100\n",
    "    base_date = np.datetime64('2009-01-01')\n",
    "    delta_days = np.timedelta64(1, 'D') * (day_codes - 1)\n",
    "    delta_minutes = np.timedelta64(30, 'm') * (time_codes - 1)\n",
    "    decoded_datetimes = base_date + delta_days + delta_minutes\n",
    "    return decoded_datetimes\n",
    "\n",
    "df_all['datetime'] = decode_datetime(df_all['datetime'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There exist duplicates due to timezone change for winter time, we drop them and resample data to hourly resolution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_all.drop_duplicates(subset=['ID', 'datetime'])\n",
    "df_all = df_all.groupby(['ID', pd.Grouper(key='datetime', freq='H')]).sum().reset_index()\n",
    "df_all = df_all.rename(columns={'ID': 'id', 'power': 'consumption'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check whether there are any missing datetime values and add them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4032\n"
     ]
    }
   ],
   "source": [
    "def count_missing_datetimes(group):\n",
    "    min_datetime = group['datetime'].min()\n",
    "    max_datetime = group['datetime'].max()\n",
    "    all_datetimes = pd.date_range(min_datetime, max_datetime, freq='1H')\n",
    "    missing = all_datetimes[~all_datetimes.isin(group['datetime'])]\n",
    "    return len(missing)\n",
    "    \n",
    "missing_counts = df_all.groupby('id').apply(count_missing_datetimes)\n",
    "print(missing_counts.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_missing_datetimes(group):\n",
    "    min_datetime = group['datetime'].min()\n",
    "    max_datetime = group['datetime'].max()\n",
    "    all_datetimes = pd.date_range(min_datetime, max_datetime, freq='1H')\n",
    "    return pd.DataFrame({'id': group['id'].iloc[0], 'datetime': all_datetimes})\n",
    "\n",
    "df_all_with_missing = df_all.groupby('id').apply(generate_missing_datetimes).reset_index(drop=True)   \n",
    "df_all = df_all_with_missing.merge(df_all, how='left', on=['id', 'datetime'])           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.to_csv('preprocessed_cbt.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c95252ec0fd7c5cb6f76d566d509abd2f82a93011f8cc5397bf70718e35dfb83"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
